NAME: diffspeaker_wav2vec2_arfriend_arkit_cond2 # Experiment name
DEBUG: False # Debug mode
ACCELERATOR: 'gpu' # Devices optioncal: “cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”
DEVICE: [4] # Index of gpus eg. [0] or [0,1,2,3]

# Training configuration
TRAIN:
  #---------------------------------
  DATASETS: ['arfriend_arkit_cond1'] # Training datasets
  NUM_WORKERS: 4 # Number of workers
  BATCH_SIZE: 2 # Size of batches (from 4)
  START_EPOCH: 0 # Start epochMMOTIONENCODER
  END_EPOCH: 9000 # End epoch
  RESUME: ''
  # RESUME: experiments/arfriend_arkit/diffusion_bias_arkit/diffspeaker_wav2vec2_arfriend_arkit_fine_base_cont # Resume training from this path
  FREEZE_PRETRAINED: False
  OPTIM:
    TYPE: AdamW # Optimizer type
    LR: 1e-6 # Learning rate (from 1e-4)

# Evaluating Configuration
EVAL:
  DATASETS: ['arfriend_arkit'] # Evaluating datasets
  BATCH_SIZE: 32 # Evaluating Batch size

# Datasets Configuration
DATASET:
  JOINT_TYPE: 'arfriend_arkit_cond1' # join type

TEST:
  CHECKPOINTS: checkpoints/arfriend/diffspeaker_wav2vec2_lipacc_arkit.ckpt # Pretrained model path
  DATASETS: ['arfriend_arkit_cond1'] # training datasets
  BATCH_SIZE: 1 # training Batch size
  SPLIT: test # split type
  REPLICATION_TIMES: 10 # replication times for each test sample

# Losses Configuration
LOSS:
  TYPE: arkit_lip_blendshapes # Losses type
  LIP_WEIGHTING: 1
  NON_LIP_WEIGHTING: 1
  DIST_SYNC_ON_STEP: True # Sync Losses on step when distributed trained

audio_encoder:
  train_audio_encoder: True
  model_name_or_path: 'facebook/wav2vec2-base-960h'
  
# Model Configuration
model:
  target: 'diffusion/diffusion_bias_modules_cond1'
  audio_encoded_dim: 768 # audio hidden dimension
  model_type: diffusion_bias_arkit_cond1 # model type
  latent_dim: 512 # latent dimension
  id_dim: 7 # the dimension of the id vector
  ff_size: 1024 # latent_dim * 2
  num_layers: 1 # number of layers
  num_heads: 4 # number of head layers
  dropout: 0.1 # dropout rate
  max_len: 600 # the attention mask maximum length
  activation: gelu # activation type
  normalize_before: True 
  require_start_token: True # start_token is need for autogressive generation only
  arch: 'default'
  predict_epsilon: False # noise or motion, motion here
  freq_shift: 0
  flip_sin_to_cos: True
  mem_attn_scale: 1.
  tgt_attn_scale: 1.
  audio_fps: 50
  hidden_fps: 30
  guidance_scale: 0 # not used
  guidance_uncondp: 0. # not used
  period: 30
  no_cross: False
  smooth_output: True
  use_audio_cond: True
  use_vertice_cond: False

DEMO:
  EAMPLE: null
  ID: null
  TEMPLATE: "datasets/lipacc_ict/templates_ict.pkl"
  PLY: "datasets/lipacc_ict/templates_ict/006Vasilisa.obj"
  FPS: 30

# Logger configuration
LOGGER:
  SACE_CHECKPOINT_EPOCH: 100 # 20
  LOG_EVERY_STEPS: 100
  VAL_EVERY_STEPS: 100000 # 200
  TENSORBOARD: True
  WANDB:
    PROJECT: null
    OFFLINE: False
    RESUME_ID: null