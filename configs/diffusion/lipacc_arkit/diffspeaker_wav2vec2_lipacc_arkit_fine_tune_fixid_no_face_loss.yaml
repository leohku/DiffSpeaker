NAME: diffspeaker_wav2vec2_lipacc_arkit_fine_tune_fixid_no_face_loss # Experiment name
DEBUG: False # Debug mode
ACCELERATOR: 'gpu' # Devices optioncal: “cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”
DEVICE: [4] # Index of gpus eg. [0] or [0,1,2,3]

# Training configuration
TRAIN:
  #---------------------------------
  DATASETS: ['lipacc_arkit'] # Training datasets
  NUM_WORKERS: 4 # Number of workers
  BATCH_SIZE: 4 # Size of batches (from 4)
  START_EPOCH: 0 # Start epochMMOTIONENCODER
  END_EPOCH: 4100 # End epoch
  # RESUME: ''
  RESUME: experiments/arfriend_arkit/diffusion_bias_arkit/diffspeaker_wav2vec2_arfriend_arkit_fine_base_cont/ # Resume training from this path
  OPTIM:
    TYPE: AdamW # Optimizer type
    LR: 1e-6 # Learning rate (from 1e-4)

# Evaluating Configuration
EVAL:
  DATASETS: ['lipacc_arkit'] # Evaluating datasets
  BATCH_SIZE: 32 # Evaluating Batch size

# Datasets Configuration
DATASET:
  JOINT_TYPE: 'lipacc_arkit' # join type

TEST:
  CHECKPOINTS: checkpoints/arfriend/diffspeaker_wav2vec2_lipacc_arkit.ckpt # Pretrained model path
  DATASETS: ['lipacc_arkit'] # training datasets
  BATCH_SIZE: 1 # training Batch size
  SPLIT: test # split type
  REPLICATION_TIMES: 10 # replication times for each test sample

# Losses Configuration
LOSS:
  TYPE: arkit_lip_blendshapes # Losses type
  LIP_WEIGHTING: 20
  NON_LIP_WEIGHTING: 0
  DIST_SYNC_ON_STEP: True # Sync Losses on step when distributed trained

audio_encoder:
  train_audio_encoder: True
  model_name_or_path: 'facebook/wav2vec2-base-960h'
  
# Model Configuration
model:
  target: 'diffusion/diffusion_bias_modules'
  audio_encoded_dim: 768 # audio hidden dimension
  model_type: diffusion_bias_arkit # model type
  latent_dim: 512 # latent dimension
  id_dim: 7 # the dimension of the id vector
  ff_size: 1024 # latent_dim * 2
  num_layers: 1 # number of layers
  num_heads: 4 # number of head layers
  dropout: 0.1 # dropout rate
  max_len: 600 # the attention mask maximum length
  activation: gelu # activation type
  normalize_before: True 
  require_start_token: True # start_token is need for autogressive generation only
  arch: 'default'
  predict_epsilon: False # noise or motion, motion here
  freq_shift: 0
  flip_sin_to_cos: True
  mem_attn_scale: 1.
  tgt_attn_scale: 1.
  audio_fps: 50
  hidden_fps: 30
  guidance_scale: 0 # not used
  guidance_uncondp: 0. # not used
  period: 30
  no_cross: False
  smooth_output: True

DEMO:
  EAMPLE: null
  ID: null
  TEMPLATE: "datasets/lipacc_ict/templates_ict.pkl"
  PLY: "datasets/lipacc_ict/templates_ict/006Vasilisa.obj"
  FPS: 30

# Logger configuration
LOGGER:
  SACE_CHECKPOINT_EPOCH: 1
  LOG_EVERY_STEPS: 100
  VAL_EVERY_STEPS: 100000 # 200
  TENSORBOARD: True
  WANDB:
    PROJECT: null
    OFFLINE: False
    RESUME_ID: null